{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00000-cda41a52-2702-4d49-9acd-1ea49c0c60b4",
        "deepnote_cell_type": "code"
      },
      "source": "from requests import get\nfrom bs4 import BeautifulSoup as Soup\nimport pandas as pd\nimport requests\nimport numpy as np\nprint(\"Libraries Installed\")",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Libraries Installed\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00001-225edc33-19af-4ffc-8853-dcd8480a59d8",
        "deepnote_cell_type": "code"
      },
      "source": "url=get(\"https://www.goodreads.com/list/show/5\")\nrequest=url.text\nsoup_data=Soup(request,\"html.parser\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-51757af7-f51e-4176-afbc-ea72dd9517e8",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating URL list as a function\ndef url_list(soup_data):\n    urls=soup_data.findAll(class_=\"bookTitle\")\n    url_list=[\"https://www.goodreads.com\"+str(list(str(url).split(\" \"))[2])[6::] for url in urls]\n    return url_list",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00003-58f9da57-144c-4399-a80a-e1a0ed26571f",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Title list as a function\ndef title_list(soup_data):\n    titles=soup_data.findAll(class_=\"bookTitle\")\n    title_list=[title.text.strip() for title in titles]\n    return title_list",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-c29462b3-5bd0-41be-bedd-6735de72d55f",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Author list as a function\ndef author_list(soup_data):\n    authors=soup_data.findAll(class_=\"authorName\")\n    author_list=[author.text for author in authors]\n    return author_list",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00005-87054fdf-505d-48a6-ac9e-92d4f475fd3a",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Rating list as a function\ndef ratings_list(soup_data):\n    ratings=soup_data.findAll(\"div\",{\"id\":\"bookMeta\"})\n    try:\n        return ratings[0].find(\"a\",{\"class\":\"gr-hyperlink\"}).text.strip().split(\"\\n\")[0].replace(\",\",\"\")\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00006-0672ce43-dce0-44b4-831c-7af6cb9bfd21",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Review list as a function\ndef reviews_list(soup_data):\n    reviews=soup_data.findAll(\"div\",{\"id\":\"bookMeta\"})\n    try:\n        return int(reviews[0].text.strip().split(\"\\n\")[-2].strip().replace(\",\",\"\"))\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00007-ba9d162e-9bd7-4a98-a04a-a151f1e3ea8c",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Avg Rating list as a function\ndef avg_list(soup_data):\n    avg_lists=[]\n    avg_ratings=soup_data.findAll(class_=\"minirating\")\n    for avg in range(len(avg_ratings)):\n        try:\n            avg_lists.append(round(float(avg_ratings[avg].text[0:4].strip())))\n        except:\n            avg_lists.append(np.nan)\n    return avg_lists",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00008-1da1b064-76c8-495d-bc47-09cfb95948b4",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Number of Page list as a function\ndef pages_list(soup_data):\n    num_pages=soup_data.findAll(\"span\",{\"itemprop\":\"numberOfPages\"})\n    try:\n        return int(num_pages[0].text.split(\" \")[0])\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00009-a2aa4e61-9577-4f5f-ac33-ed9e9e4c1cc5",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Published Year list as a function\ndef published_list(soup_data):\n    published_year=soup_data.findAll(\"div\",{\"id\":\"details\"})\n    published_list=[]\n    try:\n        return published_year[0].text.split(\"\\n\")[4][-4::]\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00010-841dfb55-f340-472c-8876-9dcb9ceaf7e9",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Series Boolean list as a function\ndef series_list(soup_data):\n    series=soup_data.findAll(\"h2\",{\"id\":\"bookSeries\"})\n    \n    try:\n        if series[0].text.strip()==\"\":\n            return 0\n        else:\n            return 1\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00011-45adb20a-9bb4-47aa-b5af-f63d36e05234",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Genres list as a function\ndef genres_list(soup_data):\n    genres=soup_data.findAll(class_=\"rightContainer\")\n    genres_lists=[]\n    try:\n        for i in range(1,10,3):\n            genres_lists.append(genres[0].text.strip().split(\"Genres\")[1].split(\"\\n\\n\\n\")[i].split(\"\\n\")[-1].strip())\n        return genres_lists[0:3]\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00012-f431e244-59bc-4471-abb9-8b5c00ed624b",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Awards list as a function\ndef awards_list(soup_data):\n    awards=soup_data.findAll(class_=\"award\")\n    try:\n        awards_lists=[award.text.strip() for award in awards]\n        return awards_lists\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00013-ddd4a855-8e8b-42a8-9fee-24e0d7b2bc09",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Places List as a Function\ndef places_list(soup_data):\n    places=soup_data.findAll(id=\"bookDataBox\")\n    try:\n        pre_list_places=places[0].text.split(\"\\nSetting\")[1].strip().split(\"Literary Awards\")[0].strip().split(\"\\n\\n\\n\")\n        places_lists=[places.strip().split(\"\\n\\n\") for places in pre_list_places ]\n        #deleting empty list values\n        filter_object = filter(lambda x: x != '', places_lists)\n        return list(filter_object)\n    except:\n        return np.nan",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00014-c570070d-02f8-4c8c-b087-e50bf9940b28",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Function soup object as input\ndef get_data(url):\n    url_get=get(url)\n    request=url_get.text\n    soup_data=Soup(request,\"html.parser\")\n    return soup_data\n\n#Creating Dataframe as a function\ndef book(url):\n    soup_data=get_data(url)\n    \n    #Creating URL List From Function\n    url_lists=url_list(soup_data)\n\n    #Creating Title List From Function\n    title_lists=title_list(soup_data)\n    \n    #Creating Author List From Function\n    author_lists=author_list(soup_data)\n    \n    #Creating Avg List From Function\n    avg_lists=avg_list(soup_data)\n    \n    pages_lists,ratings_lists,reviews_lists,published_lists,series_lists,genres_lists,awards_lists,places_lists=[],[],[],[],[],[],[],[]\n\n    \n    #Creating \"for loop\" for iterating through the pages\n    for urls in url_lists:\n        soup_data2=get_data(urls)\n        \n        #Creating Pages List From Function\n        pages_lists.append(pages_list(soup_data2))\n        \n        #Creating Ratings List From Function\n        ratings_lists.append(ratings_list(soup_data2))\n        \n        #Creating Reviews List From Function\n        reviews_lists.append(reviews_list(soup_data2))\n        \n        #Creating Published Year List From Function\n        published_lists.append(published_list(soup_data2))\n        \n        #Creating Series Boolean List From Function\n        series_lists.append(series_list(soup_data2))\n        \n        #Creating Genres List From Function\n        genres_lists.append(genres_list(soup_data2))\n        \n        #Creating Awards List From Function\n        awards_lists.append(awards_list(soup_data2))\n          \n        #Creating Places List From Function\n        places_lists.append(places_list(soup_data2))\n\n    df_dict={\"URL\":url_lists,\"Title\":title_lists,\"Author\":author_lists,\"Number of Ratings\":ratings_lists,\"Number of Reviews\":reviews_lists,\n        \"Average Ratings\":avg_lists,\"Number of Pages\":pages_lists,\"Published Year\":published_lists,\n        \"Series\":series_lists,\"Genres\":genres_lists,\"Awards\":awards_lists,\"Places\":places_lists}\n    return df_dict\n\n\nurl=\"https://www.goodreads.com/list/show/5\"\n    \n    ",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00015-fee921f9-e268-4f6a-8658-9236a36c292b",
        "deepnote_cell_type": "code"
      },
      "source": "#Creating Column Names as a List\ncolumn_names=[\"URL\",\"Title\",\"Author\",\"Number of Ratings\",\"Number of Reviews\",\n        \"Average Ratings\",\"Number of Pages\",\"Published Year\",\n        \"Series\",\"Genres\",\"Awards\",\"Places\"]\n#Creating list page for 10 pages of books\nmain_page=\"https://www.goodreads.com/list/show/5.Best_Books_of_the_Decade_2000s?page=\"\nlist_pages={main_page+str(page) for page in range(2,11)}\n\n#First page defined as main page\nmain_page=book(url)\n\n#\"for loop\" for other pages\nfor page in list_pages:\n    next_page=book(page)\n    for column in column_names:\n        main_page[column].extend(next_page[column])\ndf=pd.DataFrame(data=main_page)",
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "arrays must all be same length",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-141-69622e477864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmain_page\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_page\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00016-f84046ef-1c10-4990-94e1-ca2ef2e5804d",
        "deepnote_cell_type": "code"
      },
      "source": "df=pd.DataFrame(data=main_page)\ndf",
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>Title</th>\n      <th>Author</th>\n      <th>Number of Ratings</th>\n      <th>Number of Reviews</th>\n      <th>Average Ratings</th>\n      <th>Number of Pages</th>\n      <th>Published Year</th>\n      <th>Series</th>\n      <th>Genres</th>\n      <th>Awards</th>\n      <th>Places</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.goodreads.com/book/show/136251.Har...</td>\n      <td>Harry Potter and the Deathly Hallows (Harry Po...</td>\n      <td>J.K. Rowling</td>\n      <td>2959288</td>\n      <td>68446.0</td>\n      <td>5.0</td>\n      <td>759.0</td>\n      <td>2007</td>\n      <td>1.0</td>\n      <td>[Fantasy, Young Adult, Fiction]</td>\n      <td>[Locus Award Nominee for Best Young Adult Nove...</td>\n      <td>[[London, England, (United Kingdom)], [Hogwart...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n      <td>The Hunger Games (The Hunger Games, #1)</td>\n      <td>Suzanne Collins</td>\n      <td>6684900</td>\n      <td>175492.0</td>\n      <td>4.0</td>\n      <td>374.0</td>\n      <td>2008</td>\n      <td>1.0</td>\n      <td>[Young Adult, Fiction, Dystopia]</td>\n      <td>[Locus Award Nominee for Best Young Adult Book...</td>\n      <td>[[District 12, Panem, Capitol, Panem, Panem, (...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.goodreads.com/book/show/1.Harry_Po...</td>\n      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n      <td>J.K. Rowling</td>\n      <td>2575144</td>\n      <td>42015.0</td>\n      <td>4.0</td>\n      <td>652.0</td>\n      <td>2006</td>\n      <td>1.0</td>\n      <td>[Fantasy, Young Adult, Fiction]</td>\n      <td>[Locus Award Nominee for Best Young Adult Nove...</td>\n      <td>[[Hogwarts School of Witchcraft and Wizardry, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.goodreads.com/book/show/6.Harry_Po...</td>\n      <td>Harry Potter and the Goblet of Fire (Harry Pot...</td>\n      <td>J.K. Rowling</td>\n      <td>2749673</td>\n      <td>49578.0</td>\n      <td>4.0</td>\n      <td>734.0</td>\n      <td>2002</td>\n      <td>1.0</td>\n      <td>[Fantasy, Young Adult, Fiction]</td>\n      <td>[Hugo Award for Best Novel (2001), Mythopoeic ...</td>\n      <td>[[Hogwarts School of Witchcraft and Wizardry,\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n      <td>J.K. Rowling</td>\n      <td>2653157</td>\n      <td>45371.0</td>\n      <td>4.0</td>\n      <td>870.0</td>\n      <td>2004</td>\n      <td>1.0</td>\n      <td>[Fantasy, Young Adult, Fiction]</td>\n      <td>[Bram Stoker Award for Works for Young Readers...</td>\n      <td>[[Hogwarts School of Witchcraft and Wizardry, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>https://www.goodreads.com/book/show/179064.The...</td>\n      <td>The Goose Girl (The Books of Bayern, #1)</td>\n      <td>Neil Gaiman</td>\n      <td>140021</td>\n      <td>10150.0</td>\n      <td>4.0</td>\n      <td>383.0</td>\n      <td>2005</td>\n      <td>1.0</td>\n      <td>[Fantasy, Young Adult, Fairy Tales]</td>\n      <td>[Mythopoeic Fantasy Award Nominee for Children...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>https://www.goodreads.com/book/show/24812.The_...</td>\n      <td>The Complete Calvin and Hobbes</td>\n      <td>Isabel Allende</td>\n      <td>36182</td>\n      <td>1048.0</td>\n      <td>5.0</td>\n      <td>1456.0</td>\n      <td>2005</td>\n      <td>1.0</td>\n      <td>[Comics, Humor, Graphic Novels]</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>https://www.goodreads.com/book/show/3432478-th...</td>\n      <td>The Forest of Hands and Teeth (The Forest of H...</td>\n      <td>Geraldine Brooks</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>https://www.goodreads.com/book/show/6048530-fi...</td>\n      <td>Finger Lickin' Fifteen (Stephanie Plum, #15)</td>\n      <td>Rick Riordan</td>\n      <td>81824</td>\n      <td>4204.0</td>\n      <td>NaN</td>\n      <td>308.0</td>\n      <td>2009</td>\n      <td>1.0</td>\n      <td>[Mystery, Fiction, Humor]</td>\n      <td>[Goodreads Choice Award Nominee for Mystery/Th...</td>\n      <td>[[Trenton, New Jersey, (United States)]]</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>https://www.goodreads.com/book/show/28078.The_...</td>\n      <td>The Birth of Venus</td>\n      <td>Dave Eggers</td>\n      <td>95662</td>\n      <td>3277.0</td>\n      <td>4.0</td>\n      <td>427.0</td>\n      <td>2004</td>\n      <td>0.0</td>\n      <td>[Historical Fiction, Fiction, Historical]</td>\n      <td>[]</td>\n      <td>[[Italy, Florence, (Italy)], [], [Other Editio...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 12 columns</p>\n</div>",
            "text/plain": "                                                   URL  \\\n0    https://www.goodreads.com/book/show/136251.Har...   \n1    https://www.goodreads.com/book/show/2767052-th...   \n2    https://www.goodreads.com/book/show/1.Harry_Po...   \n3    https://www.goodreads.com/book/show/6.Harry_Po...   \n4    https://www.goodreads.com/book/show/2.Harry_Po...   \n..                                                 ...   \n995  https://www.goodreads.com/book/show/179064.The...   \n996  https://www.goodreads.com/book/show/24812.The_...   \n997  https://www.goodreads.com/book/show/3432478-th...   \n998  https://www.goodreads.com/book/show/6048530-fi...   \n999  https://www.goodreads.com/book/show/28078.The_...   \n\n                                                 Title            Author  \\\n0    Harry Potter and the Deathly Hallows (Harry Po...      J.K. Rowling   \n1              The Hunger Games (The Hunger Games, #1)   Suzanne Collins   \n2    Harry Potter and the Half-Blood Prince (Harry ...      J.K. Rowling   \n3    Harry Potter and the Goblet of Fire (Harry Pot...      J.K. Rowling   \n4    Harry Potter and the Order of the Phoenix (Har...      J.K. Rowling   \n..                                                 ...               ...   \n995           The Goose Girl (The Books of Bayern, #1)       Neil Gaiman   \n996                     The Complete Calvin and Hobbes    Isabel Allende   \n997  The Forest of Hands and Teeth (The Forest of H...  Geraldine Brooks   \n998       Finger Lickin' Fifteen (Stephanie Plum, #15)      Rick Riordan   \n999                                 The Birth of Venus       Dave Eggers   \n\n    Number of Ratings  Number of Reviews  Average Ratings  Number of Pages  \\\n0             2959288            68446.0              5.0            759.0   \n1             6684900           175492.0              4.0            374.0   \n2             2575144            42015.0              4.0            652.0   \n3             2749673            49578.0              4.0            734.0   \n4             2653157            45371.0              4.0            870.0   \n..                ...                ...              ...              ...   \n995            140021            10150.0              4.0            383.0   \n996             36182             1048.0              5.0           1456.0   \n997               NaN                NaN              4.0              NaN   \n998             81824             4204.0              NaN            308.0   \n999             95662             3277.0              4.0            427.0   \n\n    Published Year  Series                                     Genres  \\\n0             2007     1.0            [Fantasy, Young Adult, Fiction]   \n1             2008     1.0           [Young Adult, Fiction, Dystopia]   \n2             2006     1.0            [Fantasy, Young Adult, Fiction]   \n3             2002     1.0            [Fantasy, Young Adult, Fiction]   \n4             2004     1.0            [Fantasy, Young Adult, Fiction]   \n..             ...     ...                                        ...   \n995           2005     1.0        [Fantasy, Young Adult, Fairy Tales]   \n996           2005     1.0            [Comics, Humor, Graphic Novels]   \n997            NaN     NaN                                        NaN   \n998           2009     1.0                  [Mystery, Fiction, Humor]   \n999           2004     0.0  [Historical Fiction, Fiction, Historical]   \n\n                                                Awards  \\\n0    [Locus Award Nominee for Best Young Adult Nove...   \n1    [Locus Award Nominee for Best Young Adult Book...   \n2    [Locus Award Nominee for Best Young Adult Nove...   \n3    [Hugo Award for Best Novel (2001), Mythopoeic ...   \n4    [Bram Stoker Award for Works for Young Readers...   \n..                                                 ...   \n995  [Mythopoeic Fantasy Award Nominee for Children...   \n996                                                 []   \n997                                                 []   \n998  [Goodreads Choice Award Nominee for Mystery/Th...   \n999                                                 []   \n\n                                                Places  \n0    [[London, England, (United Kingdom)], [Hogwart...  \n1    [[District 12, Panem, Capitol, Panem, Panem, (...  \n2    [[Hogwarts School of Witchcraft and Wizardry, ...  \n3    [[Hogwarts School of Witchcraft and Wizardry,\\...  \n4    [[Hogwarts School of Witchcraft and Wizardry, ...  \n..                                                 ...  \n995                                                NaN  \n996                                                NaN  \n997                                                NaN  \n998           [[Trenton, New Jersey, (United States)]]  \n999  [[Italy, Florence, (Italy)], [], [Other Editio...  \n\n[1000 rows x 12 columns]"
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00017-b075e224-89e1-4134-854b-6667b78c6d9e",
        "deepnote_cell_type": "code"
      },
      "source": "df.to_csv(r'C:\\Users\\aktum\\Documents\\GitHub\\Good_reads_Best_2000s\\Data.csv', index = False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00018-969d4559-72ea-4e34-8e75-1c926d1aeada",
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a0867bd3-5624-476b-af8a-bd1f917bd510' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "deepnote_notebook_id": "63d01a1e-b01f-4bd7-b9a9-56dd604c127b",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}